categories:

  - data-filter: Lighting
    category-name: Lighting

  - data-filter: Cognitive Science
    category-name: Cognitive Science
  
  - data-filter: Other
    category-name: Other


projects:

  - title: From neutral to angry faces, with different races
    system-name: 
    gif: 
    conference: Toyohashi University of Technology (2024)
    conference-web: https://www.tut.ac.jp/english/
    status: In Progress
    authors: Patricia de Torres Coll.
    pdf: 
    code: 
    demo: 
    slides: 
    talk: 
    abstract-less: People tend to recognize better the emotions of their own ethiniticity. This study implements virtual reality in order to study how well participants can determine between asian and caucasian avatars. 
    abstract-more: Technology and softwares used were Virtual reality equipment, Unity, C#, FaceGenModeller and RStudio.
    tag: avatar_emotions
    category: Cognitive Science

  - title: Cross-Modality in Virtual Reality
    system-name: 
    gif: assets/img/casestudy.jpg
    conference: Toyohashi University of Technology (2023)
    conference-web: https://www.tut.ac.jp/english/
    status: 
    authors: Patricia de Torres Coll, Amrit Shaw, Aryaman Sharma, Nam Nguyen Hoang and Ioh Nishijima.
    pdf: 
    code: 
    demo: 
    slides: 
    talk:
    abstract-less: This project aimed to explore the impact of a 3D virtual reality (VR) environment on the Sound-Induced Flash Illusion (SIFI), where auditory stimuli significantly affect visual perception. Previous experiments revealed that a single flash accompanied by multiple beeps led observers to perceive multiple flashes. We hypothesize that conducting these experiments in VR will enhance the cross-modal effect on visual perception due to the immersive nature of the environment. The study seeks to investigate how the three-dimensional aspects of VR influence participants' perception of auditory and visual stimuli, potentially amplifying or altering the SIFI phenomenon.
    abstract-more: The experiment was created in virtual reality, 4 male and 1 female participant were recruited for the experiment with ages ranging between 23 and 27 years. All the participants were of different nationalities and had normal or corrected visions.  Two types of stimuli were used (Beeps & Flash). These stimuli were played either once or twice intercalated in order to analyse the illusions e.g. 1 flash, 1 beep (100% of accuracy), 1 flash, 2 beep(Fission illusion, we could not conclude any result because there were not enough participants), 2 flash, 2 beeps (Almost 100% of accuracy), 2 flash, 1 beep (Fusion illusion detected. However the accuracy was higher than 60%, so the illusion was not very high). Due to VR provides greater immersion, cross-modality persists but it is reduced in VR. Technology and softwares used were Virtual reality equipment, Unity, C# and RStudio.
    tag: casestudyXR
    category: Cognitive Science
  
  - title: Tunable lighting luminaire
    system-name: 
    gif: assets/img/lightingtech.jpg
    conference: KU Leuven (2023)
    conference-web: https://www.kuleuven.be/kuleuven
    status: 
    authors: Patricia de Torres Coll, Amrit Shaw, Yasmina Feriel Djelil.
    pdf: 
    code: 
    demo: 
    slides: 
    talk: 
    abstract-less: The aim of this proejct was to creting a lighting luminaire that satisfied certain requirements (Volume of 8x8x8 cm^{3}. Total output power-Minimally 2400 lumen within a beam half-opening angle of 12Â°. Minimal luminaire efficacy 120 lumen/W. Tunable CCT from 2700 K to 6500 K (along the planckian locus, duv = < 0.006. CRI > = 80.). In addition, there should not have visible colour gradients or disturbing illuminance gradients in the beam pattern.) These requirements needed to be satisfied with available products in the market. The approach was studied with an optical, thermal and components report. 
    abstract-more: The tools and softwares used were LightTools, CAD, Sim Scale, Blender, Python and the materials to construct the lamp (LEDs, Wires, HeatSink, Reflector).
    tag: lightingTech
    category: Lighting

  - title: Spectrally tunable lamp
    system-name: 
    gif: assets/img/lamp.png
    conference: KU Leuven (2023)
    conference-web: https://www.kuleuven.be/kuleuven
    status: 
    authors: Patricia de Torres Coll, Yasmina Feriel Djelil, Artemis Georgopoulou and Ayazhan Assanova.
    pdf: 
    code: 
    demo: 
    slides: 
    talk: 
    abstract-less: The project entailed controlling a spectrally tunable lamp using different Python packages(Numpy, Luxpy, Matplotlib... etc). To achieve the final aim, this project was divided into 4 main tasks. 1. Controlling the lamp with the supplied DMX controller. 2. Callibrating the lamp to relate the LED light intensity to the LED digital drive value. 3. Achieve the color mixing of the lamp. 4. Spectral optimization of the system.
    abstract-more: The tools and languages used were Python (luxpy), ADJ 12PX HEX lamp, DMX USB Pro Interface and Spectroradiometer  Jeti Specbos 1211L.
    tag: lightingSc
    category: Lighting

  - title: Complete integration of robot arm in a virtual environment
    system-name: 
    gif: assets/img/robotarm.jpg
    conference: University of Eastern Finland
    conference-web: https://www.uef.fi/en
    status: 
    authors: Patricia de Torres Coll, Amrit Shaw, Aryaman Sharma, Chihiro Tone and Aslak Ton.
    pdf: 
    code: 
    demo: 
    slides: 
    talk: 
    abstract-less: This project focused on how to control the Universal Robot UR3e using a VR controller, as well as a virtual stand in for the physical robot which can be moved in the virtual environment and interact with some virtual objects. The VR controller gave (x, y, z)-coordinates, and the project was to figure out rotations of the Robot Arm in order to hit this given (x, y, z)-position. This process is called inverse kinematics. In general this problem has been solved, and libraries exist that solve inverse kinematics systems. This project wanted to work from the ground up to solve these systems in order to understand the underlying process.
    abstract-more: A virtual environment was created where there was a virtual robot arm with the same kinetics as the real one. Moving the controllers, we were able to move the real robot arm. The tools and softwares used were Universal Robot UR3e, Virtual Reality equipment, Python, Unity and C#.
    tag: robot
    category: Other

  